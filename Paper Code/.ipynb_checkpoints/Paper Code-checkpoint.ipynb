{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3de7cca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import h2o\n",
    "h2o.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3e1947f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Draw box diagram\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "plt.rcParams['font.sans-serif'] =['Times New Roman'] \n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "data = pd.read_csv('data_origin.csv')\n",
    "columns=list(data.columns)\n",
    "unit=[\"( ℃ )\",\"( min )\",\"( mm )\",\"\",\"( ℃ )\",\"( d )\",\"( % )\",\"( % )\",\"( % )\",\"( mL CH$_4$/gVS )\"]\n",
    "data.dropna(inplace=True)\n",
    "fig, axs = plt.subplots(2, 5, figsize=(28,15))\n",
    "columns = data.columns\n",
    "# my_palette = [\"blue\", \"orange\", \"green\", \"red\", \"purple\"]\n",
    "# colors = sns.color_palette(my_palette, n_colors=len(columns))\n",
    "colors = sns.color_palette(\"RdYlGn\", n_colors=len(columns))\n",
    "for ax, col, color, letter ,uni in zip(axs.flatten(), columns, colors, list(\"abcdefghij\"),unit):\n",
    "    sns.boxplot(data=data[col], color=color, ax=ax)\n",
    "    sns.stripplot(data=data[col], color=\"black\",ax=ax,jitter=True)\n",
    "    ax.text(-0.25, 1.05, f\"({letter})\", transform=ax.transAxes, fontsize=30, fontweight='bold')\n",
    "    ax.tick_params(axis='y', labelsize=19)\n",
    "    ax.set_xticklabels('')\n",
    "    ax.set_xlabel(col, fontweight='bold',fontsize=23)\n",
    "    ax.set_ylabel(uni, fontweight='bold',fontsize=23,labelpad=10)\n",
    "plt.subplots_adjust(wspace=0.5)\n",
    "plt.savefig(\"./箱式图.png\",dpi=600)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25877a2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plotting Pearson matrices\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import seaborn as sns\n",
    "from pylab import *\n",
    "from matplotlib import pyplot as plt\n",
    "plt.rcParams['font.sans-serif'] =['Times New Roman'] \n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "from pandas.plotting import scatter_matrix\n",
    "from sklearn.preprocessing import StandardScaler, Normalizer, MinMaxScaler\n",
    "from sklearn.metrics import r2_score, explained_variance_score, mean_squared_error,mean_absolute_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "data = pd.read_csv('data_origin.csv')\n",
    "x=data.shape[1]\n",
    "a=data.iloc[:,0:x].corr()\n",
    "plt.subplots(figsize=(28,18),dpi=600)\n",
    "mask = np.zeros_like(a, dtype=np.bool)   \n",
    "mask[np.tril_indices_from(mask)]= True    \n",
    "h=sns.heatmap(a,annot=True, vmax=1, square=True,cbar_kws={\"shrink\": 0.8},linecolor=\"black\",annot_kws={'size':27,\"weight\":'bold'},linewidths=2,cbar=False)\n",
    "cb=h.figure.colorbar(h.collections[0]) \n",
    "cb.ax.tick_params(labelsize=24,size=2,width=2) \n",
    "plt.xticks(fontsize=30,rotation=90,weight='bold')\n",
    "plt.yticks(fontsize=30,rotation=360,weight='bold')\n",
    "plt.savefig(\"./Figure\",dpi=600,transparent=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "169333c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Light GBM for data filling\n",
    "from sklearn.experimental import enable_iterative_imputer \n",
    "from sklearn.impute import IterativeImputer\n",
    "from lightgbm import LGBMRegressor\n",
    "from h2o.automl import H2OAutoML\n",
    "from sklearn.metrics import r2_score, explained_variance_score, mean_squared_error,mean_absolute_error\n",
    "\n",
    "data = pd.read_csv('data_origin.csv')\n",
    "LGBR = LGBMRegressor()\n",
    "imputer_lightgbm = IterativeImputer(max_iter = 30, \n",
    "                           random_state = 1, \n",
    "                           estimator = LGBR)\n",
    "imputer_lightgbm.fit(data) \n",
    "imputer_lightgbm_data = imputer_lightgbm.transform(data) \n",
    "imputer_lightgbm_data = pd.DataFrame(imputer_lightgbm_data,columns=data.columns)\n",
    "imputer_lightgbm_data.to_csv(\"./imputer_data/imputer_lightgbm_data.csv\")\n",
    "gujunmu=h2o.upload_file(\"./imputer_data/imputer_lightgbm_data.csv\")\n",
    "gujunmu= gujunmu[:,1:]\n",
    "gujunmu_split=gujunmu.split_frame(ratios=[0.8],seed=1)\n",
    "gujunmu_train=gujunmu_split[0]\n",
    "gujunmu_test=gujunmu_split[1]\n",
    "preditors=list(gujunmu.columns)\n",
    "preditors.remove(\"Cumulative methane production\")\n",
    "aml60 = H2OAutoML(max_runtime_secs=60)\n",
    "aml60.train(x = preditors,y = \"Cumulative methane production\",training_frame=gujunmu_train,validation_frame=gujunmu_test)\n",
    "preds_train= aml60.leader.predict(gujunmu_train)\n",
    "preds = aml60.leader.predict(gujunmu_test)\n",
    "y_train=gujunmu_train[:,-1]\n",
    "y_train= h2o.as_list(y_train)\n",
    "y_valid=gujunmu_test[:,-1]\n",
    "y_valid = h2o.as_list(y_valid)\n",
    "preds= h2o.as_list(preds)\n",
    "preds_train= h2o.as_list(preds_train)\n",
    "score训练集 = r2_score(y_train,preds_train)\n",
    "score训练集=round(score训练集, 2)\n",
    "score测试集 = r2_score(y_valid,preds)\n",
    "score测试集=round(score测试集, 2)\n",
    "rmse_test=round(sqrt(mean_squared_error(y_valid,preds)), 2)\n",
    "rmse_train=round(sqrt(mean_squared_error(y_train,preds_train)), 2)\n",
    "result = '''\n",
    "LightGBM填补结果:\n",
    "Train R$^2$:{}\n",
    "Train RMSE: {}\n",
    "Test R$^2$:{}\n",
    "Test RMSE: {}\n",
    "'''.format(score训练集,rmse_train,score测试集, rmse_test)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23e44a67",
   "metadata": {},
   "outputs": [],
   "source": [
    "#RF for data filling\n",
    "from sklearn.experimental import enable_iterative_imputer \n",
    "from sklearn.impute import IterativeImputer\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from h2o.automl import H2OAutoML\n",
    "from sklearn.metrics import r2_score, explained_variance_score, mean_squared_error,mean_absolute_error\n",
    "data = pd.read_csv('data_origin.csv')\n",
    "RF = RandomForestRegressor()\n",
    "imputer_rf = IterativeImputer(max_iter = 30, \n",
    "                           random_state = 1, \n",
    "                           estimator = RF)\n",
    "\n",
    "imputer_rf.fit(data) \n",
    "imputer_rf_data = imputer_rf.transform(data) \n",
    "imputer_rf_data = pd.DataFrame(imputer_rf_data,columns=data.columns)\n",
    "imputer_rf_data.to_csv(\"./imputer_data/imputer_rf_data.csv\")\n",
    "gujunmu=h2o.upload_file(\"./imputer_data/imputer_rf_data.csv\")\n",
    "gujunmu= gujunmu[:,1:]\n",
    "gujunmu_split=gujunmu.split_frame(ratios=[0.8],seed=1)\n",
    "gujunmu_train=gujunmu_split[0]\n",
    "gujunmu_test=gujunmu_split[1]\n",
    "preditors=list(gujunmu.columns)\n",
    "preditors.remove(\"Cumulative methane production\")\n",
    "aml60 = H2OAutoML(max_runtime_secs=60)\n",
    "aml60.train(x = preditors,y = \"Cumulative methane production\",training_frame=gujunmu_train,validation_frame=gujunmu_test)\n",
    "preds_train= aml60.leader.predict(gujunmu_train)\n",
    "preds = aml60.leader.predict(gujunmu_test)\n",
    "y_train=gujunmu_train[:,-1]\n",
    "y_train= h2o.as_list(y_train)\n",
    "y_valid=gujunmu_test[:,-1]\n",
    "y_valid = h2o.as_list(y_valid)\n",
    "preds= h2o.as_list(preds)\n",
    "preds_train= h2o.as_list(preds_train)\n",
    "score训练集 = r2_score(y_train,preds_train)\n",
    "score训练集=round(score训练集, 2)\n",
    "score测试集 = r2_score(y_valid,preds)\n",
    "score测试集=round(score测试集, 2)\n",
    "rmse_test=round(sqrt(mean_squared_error(y_valid,preds)), 2)\n",
    "rmse_train=round(sqrt(mean_squared_error(y_train,preds_train)), 2)\n",
    "result = '''\n",
    "RF填补结果:\n",
    "Train R$^2$:{}\n",
    "Train RMSE: {}\n",
    "Test R$^2$:{}\n",
    "Test RMSE: {}\n",
    "'''.format(score训练集,rmse_train,score测试集, rmse_test)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59af7060",
   "metadata": {},
   "outputs": [],
   "source": [
    "#KNN for data filling\n",
    "from sklearn.experimental import enable_iterative_imputer \n",
    "from sklearn.impute import IterativeImputer\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from h2o.automl import H2OAutoML\n",
    "from sklearn.metrics import r2_score, explained_variance_score, mean_squared_error,mean_absolute_error\n",
    "data = pd.read_csv('data_origin.csv')\n",
    "KNN = KNeighborsRegressor(n_neighbors=10, p = 1) \n",
    "\n",
    "imputer_knn = IterativeImputer(max_iter = 30, \n",
    "                           random_state = 1, \n",
    "                           estimator = KNN)\n",
    "imputer_knn.fit(data) \n",
    "imputer_knn_data = imputer_knn.transform(data) \n",
    "imputer_knn_data = pd.DataFrame(imputer_knn_data,columns=data.columns)\n",
    "imputer_rf_data.to_csv(\"./imputer_data/imputer_knn_data.csv\")\n",
    "gujunmu=h2o.upload_file(\"./imputer_data/imputer_knn_data.csv\")\n",
    "gujunmu= gujunmu[:,1:]\n",
    "gujunmu_split=gujunmu.split_frame(ratios=[0.8],seed=1)\n",
    "gujunmu_train=gujunmu_split[0]\n",
    "gujunmu_test=gujunmu_split[1]\n",
    "preditors=list(gujunmu.columns)\n",
    "preditors.remove(\"Cumulative methane production\")\n",
    "aml60 = H2OAutoML(max_runtime_secs=60)#,\n",
    "aml60.train(x = preditors,y = \"Cumulative methane production\",training_frame=gujunmu_train,validation_frame=gujunmu_test)\n",
    "preds_train= aml60.leader.predict(gujunmu_train)\n",
    "preds = aml60.leader.predict(gujunmu_test)\n",
    "y_train=gujunmu_train[:,-1]\n",
    "y_train= h2o.as_list(y_train)\n",
    "y_valid=gujunmu_test[:,-1]\n",
    "y_valid = h2o.as_list(y_valid)\n",
    "preds= h2o.as_list(preds)\n",
    "preds_train= h2o.as_list(preds_train)\n",
    "score训练集 = r2_score(y_train,preds_train)\n",
    "score训练集=round(score训练集, 2)\n",
    "score测试集 = r2_score(y_valid,preds)\n",
    "score测试集=round(score测试集, 2)\n",
    "rmse_test=round(sqrt(mean_squared_error(y_valid,preds)), 2)\n",
    "rmse_train=round(sqrt(mean_squared_error(y_train,preds_train)), 2)\n",
    "result = '''\n",
    "KNN填补结果:\n",
    "Train R$^2$:{}\n",
    "Train RMSE: {}\n",
    "Test R$^2$:{}\n",
    "Test RMSE: {}\n",
    "'''.format(score训练集,rmse_train,score测试集, rmse_test)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bd3660c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import data\n",
    "gujunmu=h2o.upload_file(\"./imputer_data/imputer_rf_data.csv\")\n",
    "gujunmu= gujunmu[:,1:]\n",
    "gujunmu.shape\n",
    "gujunmu.describe()\n",
    "gujunmu_split=gujunmu.split_frame(ratios=[0.8],seed=1)\n",
    "gujunmu_train=gujunmu_split[0]\n",
    "gujunmu_test=gujunmu_split[1]\n",
    "print(gujunmu_train.shape,gujunmu_test.shape)\n",
    "preditors=list(gujunmu.columns)\n",
    "preditors.remove(\"Cumulative methane production\")\n",
    "preditors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cb665bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Run 60s results\n",
    "from h2o.automl import H2OAutoML\n",
    "aml60=H2OAutoML(max_runtime_secs=60)#,\n",
    "aml60.train(x=preditors,y=\"Cumulative methane production\",training_frame=gujunmu_train,validation_frame=gujunmu_test)\n",
    "print(aml60.leaderboard)\n",
    "aml60.leader.model_performance(gujunmu_test)\n",
    "preds = aml60.leader.predict(gujunmu_test)\n",
    "preds_train= aml60.leader.predict(gujunmu_train)\n",
    "from sklearn.metrics import r2_score, explained_variance_score, mean_squared_error,mean_absolute_error\n",
    "y_valid=gujunmu_test[:,-1]\n",
    "y_valid = h2o.as_list(y_valid)\n",
    "y_train=gujunmu_train[:,-1]\n",
    "y_train= h2o.as_list(y_train)\n",
    "preds= h2o.as_list(preds)\n",
    "preds_train= h2o.as_list(preds_train)\n",
    "result = '''\n",
    "Train R$^2$:{}\n",
    "Train RMSE: {}\n",
    "Test R$^2$:{}\n",
    "Test RMSE: {}\n",
    "'''.format(score训练集,rmse_train,score测试集, rmse)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deec62d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Run 300s results\n",
    "from h2o.automl import H2OAutoML\n",
    "aml300=H2OAutoML(max_runtime_secs=300)\n",
    "aml300.train(x=preditors,y=\"Cumulative methane production\",training_frame=gujunmu_train,validation_frame=gujunmu_test)\n",
    "print(aml300.leaderboard)\n",
    "aml300.leader.model_performance(gujunmu_test)\n",
    "preds = aml300.leader.predict(gujunmu_test)\n",
    "preds_train= aml300.leader.predict(gujunmu_train)\n",
    "from sklearn.metrics import r2_score, explained_variance_score, mean_squared_error,mean_absolute_error\n",
    "y_valid=gujunmu_test[:,-1]\n",
    "y_valid = h2o.as_list(y_valid)\n",
    "y_train=gujunmu_train[:,-1]\n",
    "y_train= h2o.as_list(y_train)\n",
    "preds= h2o.as_list(preds)\n",
    "preds_train= h2o.as_list(preds_train)\n",
    "result = '''\n",
    "Train R$^2$:{}\n",
    "Train RMSE: {}\n",
    "Test R$^2$:{}\n",
    "Test RMSE: {}\n",
    "'''.format(score训练集,rmse_train,score测试集, rmse)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "047c4033",
   "metadata": {},
   "source": [
    "Because it is the same code, it will not be repeated. The latter time periods are 600, 900, 1200, 1500, 1800, 2100.\n",
    "The optimal run result is 1500s, so the derived model at 1500s is used for subsequent applications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "297d812c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Run 1500s results(max)\n",
    "from h2o.automl import H2OAutoML\n",
    "aml1500=H2OAutoML(max_runtime_secs=1500)#,\n",
    "aml1500.train(x=preditors,y=\"Cumulative methane production\",training_frame=gujunmu_train,validation_frame=gujunmu_test)\n",
    "print(aml1500.leaderboard)\n",
    "result=aml1500.leader.model_performance(gujunmu_test)\n",
    "preds = aml1500.predict(gujunmu_test)\n",
    "preds_train= aml1500.predict(gujunmu_train)\n",
    "from sklearn.metrics import r2_score, explained_variance_score, mean_squared_error,mean_absolute_error\n",
    "y_valid=gujunmu_test[:,-1]\n",
    "y_valid = h2o.as_list(y_valid)\n",
    "y_train=gujunmu_train[:,-1]\n",
    "y_train= h2o.as_list(y_train)\n",
    "preds= h2o.as_list(preds)\n",
    "preds_train= h2o.as_list(preds_train)\n",
    "result = '''\n",
    "Train R$^2$:{}\n",
    "Train RMSE: {}\n",
    "Test R$^2$:{}\n",
    "Test RMSE: {}\n",
    "'''.format(score训练集,rmse_train,score测试集, rmse)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a9d890fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model\n",
    "# model_path = h2o.save_model(model=aml1500.leader, path=\"./Best_model/\", force=True)\n",
    "# print(model_path)\n",
    "best_model = h2o.load_model(\"D:\\machine learning\\水热机器学习\\Best_model\\GBM_grid_1_AutoML_3_20230310_90755_model_125\")\n",
    "# # load the model\n",
    "# saved_model = h2o.load_model(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7beaa99",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Residual Analysis\n",
    "ra_plot = best_model.residual_analysis_plot(gujunmu,figsize=(8,5))\n",
    "plt.xticks(fontsize=15)\n",
    "plt.yticks(fontsize=15)\n",
    "plt.xlabel(\"Fitted\",fontsize=15,weight=\"bold\")\n",
    "plt.ylabel(\"Residuals\", fontsize=15,weight=\"bold\")\n",
    "plt.title(\"Residual Analysis for Best GBM\", fontsize=15,weight=\"bold\")\n",
    "plt.savefig(\"残差分析图\", dpi=600, transparent=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bddb96f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#learning curve plot\n",
    "learning_curve_plot = best_model.learning_curve_plot(figsize=(8,5))\n",
    "plt.xticks(fontsize=15)\n",
    "plt.yticks(fontsize=15)\n",
    "plt.xlabel(\"Number of trees\",fontsize=15,weight=\"bold\")\n",
    "plt.ylabel(\"RMSE\", fontsize=15,weight=\"bold\")\n",
    "plt.title(\"Learning Curve for Best GBM\", fontsize=15,weight=\"bold\")\n",
    "plt.savefig(\"学习曲线图\", dpi=600, transparent=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90290e2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Draw the fit graph\n",
    "preds = best_model.predict(gujunmu_test)\n",
    "preds_train= best_model.predict(gujunmu_train)\n",
    "from sklearn.metrics import r2_score, explained_variance_score, mean_squared_error,mean_absolute_error\n",
    "y_valid=gujunmu_test[:,-1]\n",
    "y_valid = h2o.as_list(y_valid)\n",
    "y_train=gujunmu_train[:,-1]\n",
    "y_train= h2o.as_list(y_train)\n",
    "preds= h2o.as_list(preds)\n",
    "preds_train= h2o.as_list(preds_train)\n",
    "import math\n",
    "import scipy.stats as stats\n",
    "from sklearn.utils.fixes import loguniform\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import seaborn as sns\n",
    "from pylab import *\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from matplotlib import pyplot as plt\n",
    "plt.rcParams['font.sans-serif'] =['Times New Roman'] \n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "from pandas.plotting import scatter_matrix\n",
    "from sklearn.preprocessing import StandardScaler, Normalizer, MinMaxScaler\n",
    "from sklearn.metrics import r2_score, explained_variance_score, mean_squared_error,mean_absolute_error\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "score训练集 = r2_score(y_train,preds_train)\n",
    "score训练集=round(score训练集, 2)\n",
    "score测试集 = r2_score(y_valid,preds)\n",
    "score测试集=round(score测试集, 2)\n",
    "print(score训练集,score测试集)\n",
    "mse = mean_squared_error(y_valid,preds)\n",
    "rmse= sqrt(mse)\n",
    "rmse=round(rmse, 2)\n",
    "mse_train=mean_squared_error(y_train,preds_train)\n",
    "rmse_train=sqrt(mse_train)\n",
    "rmse_train=round(rmse_train, 2)\n",
    "result = '''\n",
    "Train R$^2$:{}\n",
    "Train RMSE: {}\n",
    "Test R$^2$:{}\n",
    "Test RMSE: {}\n",
    "'''.format(score训练集,rmse_train,score测试集, rmse)\n",
    "print(result)\n",
    "res= pd.concat([y_train,preds_train],axis=1)\n",
    "res.columns = ['Actual Biogas Production (m$^3$/t VS)','Predict Biogas Production (m$^3$/t VS)']\n",
    "ace1=pd.concat([y_valid,preds],axis=1)\n",
    "ace1.columns = ['Actual Biogas Production (m$^3$/t VS)','Predict Biogas Production (m$^3$/t VS)']\n",
    "font2 = {'family' : 'Times New Roman',\n",
    "'size'   : 20}\n",
    "from matplotlib import pyplot as plt\n",
    "plt.rcParams['font.sans-serif'] =['Times New Roman'] \n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "plt.figure(figsize=(5, 5), dpi=600)\n",
    "ax1=sns.jointplot(data=res,x='Actual Biogas Production (m$^3$/t VS)',y='Predict Biogas Production (m$^3$/t VS)',\n",
    "                  kind='reg',color='red',xlim=(0,600),ylim=(0,600),marker=\"o\",scatter_kws={'s': 50, 'alpha': 0.5})\n",
    "plt.xticks(fontsize=15)\n",
    "plt.yticks(fontsize=15)\n",
    "plt.xlabel(\"Actual Cumulative methane production (mL CH$_4$/gVS)\",fontsize=15,weight=\"bold\")\n",
    "plt.ylabel(\"Predict Cumulative methane production (mL CH$_4$/gVS)\",fontsize=15,weight=\"bold\")\n",
    "ax2=sns.jointplot(data=ace1,x='Actual Biogas Production (m$^3$/t VS)',y='Predict Biogas Production (m$^3$/t VS)',\n",
    "                  kind='reg',color='#20B2AA',xlim=(0,600),ylim=(0,600),marker=\"o\",scatter_kws={'s': 70, 'alpha': 0.5})\n",
    "plt.xticks(fontsize=15)\n",
    "plt.yticks(fontsize=15)\n",
    "plt.xlabel(\"Actual Cumulative methane production (mL CH$_4$/gVS)\",fontsize=15,weight=\"bold\")\n",
    "plt.ylabel(\"Predict Cumulative methane production (mL CH$_4$/gVS)\",fontsize=15,weight=\"bold\")\n",
    "plt.text(50,400,result,font2,weight=\"bold\")\n",
    "ax1.savefig(\"train.png\",dpi=300)\n",
    "ax2.savefig(\"test.png\",dpi=300)\n",
    "plt.show()\n",
    "from PIL import Image\n",
    "def blend_two_images():\n",
    "\n",
    "    img1 = Image.open( \"train.png\")\n",
    "\n",
    "    img1 = img1.convert('RGBA')\n",
    "\n",
    "    img2 = Image.open( \"test.png\")\n",
    "\n",
    "    img2 = img2.convert('RGBA')\n",
    "\n",
    "    img = Image.blend(img1, img2, 0.7)\n",
    "\n",
    "    img.show()\n",
    "    \n",
    "\n",
    "    img.save( \"预测图.png\")\n",
    "\n",
    "    return\n",
    "\n",
    "blend_two_images()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adf6d5a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate MAPE\n",
    "from sklearn.experimental import enable_iterative_imputer \n",
    "from sklearn.impute import IterativeImputer\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def mape(actual, predict):\n",
    "    actual, predict = np.array(actual), np.array(predict)\n",
    "    return np.mean(np.abs((actual - predict) / actual)) *100\n",
    "\n",
    "#No nan MAPE\n",
    "software_test = h2o.upload_file(\"data_software_test.csv\")\n",
    "actual = np.array(h2o.as_list(software_test[:,-1]))\n",
    "predict = np.array(h2o.as_list(best_model.predict(software_test[:,:-1]))) \n",
    "mape_value = mape(actual, predict)\n",
    "print(\"MAPE(No Nan): {:.2f}%\".format(mape_value))\n",
    "\n",
    "#Conclude Nan MAPE\n",
    "#import data\n",
    "# software_test_nan = h2o.upload_file(\"data_software_test_nan.csv\")\n",
    "# software_test_nan=h2o.as_list(software_test_nan)\n",
    "# #Use RF filled the nan data\n",
    "# data = pd.read_csv(\"./imputer_data/imputer_rf_data.csv\")\n",
    "# data = data.iloc[:,1:]\n",
    "# RF = RandomForestRegressor()\n",
    "# imputer_rf = IterativeImputer(max_iter = 30, \n",
    "#                            random_state = 1, \n",
    "#                            estimator = RF)\n",
    "# imputer_rf.fit(data) \n",
    "# imputer_rf_data_nan = imputer_rf.transform(software_test_nan) \n",
    "# imputer_rf_data_nan = pd.DataFrame(imputer_rf_data_nan,columns=data.columns)\n",
    "# imputer_rf_data_nan =  h2o.H2OFrame.from_python(imputer_rf_data_nan)\n",
    "imputer_rf_data_nan =  h2o.upload_file(\"imputer_rf_sofatware_nan_data.csv\")\n",
    "#Calculate conclude nan MAPE\n",
    "actual_nan = np.array(h2o.as_list(imputer_rf_data_nan[:,-1]))\n",
    "predict_nan = np.array(h2o.as_list(best_model.predict(imputer_rf_data_nan[:,:-1])))\n",
    "mape_value_nan = mape(actual_nan, predict_nan)\n",
    "print(\"MAPE(Conclude Nan): {:.2f}%\".format(mape_value_nan))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13f75eb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Variable Importance Graph\n",
    "ra_plot = best_model.varimp_plot()\n",
    "plt.xticks(fontsize=15)\n",
    "plt.yticks(fontsize=15,weight=\"bold\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69822262",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate SHAP Values based on the best model\n",
    "class H2OWrapper:\n",
    "    import h2o\n",
    "    def __init__(self, h2o_best_model, feature_names):\n",
    "        self.ag_model = h2o_best_model\n",
    "        self.feature_names = feature_names\n",
    "    \n",
    "    def predict(self, X):\n",
    "        import h2o\n",
    "        if isinstance(X, pd.Series):\n",
    "            X = X.values.reshape(1,-1)\n",
    "        if not isinstance(X, pd.DataFrame):\n",
    "            X = pd.DataFrame(X, columns=self.feature_names)\n",
    "            X = h2o.H2OFrame(X)\n",
    "        return self.h2o.as_list(h2o_best_model.predict(X))\n",
    "    \n",
    "import shap\n",
    "X_x_summary = shap.kmeans(data.iloc[:,1:-1],10)\n",
    "print(\"Baseline feature-values: \\n\", X_x_summary)\n",
    "\n",
    "ag_wrapper = H2OWrapper(h2o_best_model, feature_names)\n",
    "explainer = shap.KernelExplainer(ag_wrapper.predict, X_x_summary)\n",
    "NSHAP_SAMPLES = 100  # how many samples to use to approximate each Shapely value, larger values will be slower\n",
    "N_VAL =100# how many datapoints from validation data should we interpret predictions for, larger values will be slower\n",
    "shap_values = explainer.shap_values(data.iloc[:,1:-1], nsamples=NSHAP_SAMPLES)\n",
    "shap_df = pd.DataFrame(shap_values, columns=data.columns[1:-1])\n",
    "shap_df.to_csv('shap_values.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9d69e77",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Perform Bayesian optimization for directed conditional search\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from bayes_opt import BayesianOptimization\n",
    "def run_secs(n):\n",
    "    for i in range (0,n):\n",
    "        path=\"./Best_model/GBM_grid_1_AutoML_3_20230310_90755_model_125/\"\n",
    "        best_model=h2o.load_model(path)\n",
    "        start=time.time()\n",
    "        def black_box_function(Hydrothermal_temperature, Hydrothermal_time, Particle_size, Solid_to_liquid_ratio, \n",
    "                               Anaerobic_temperature, Anaerobic_time, Lignin, Cellulose, Hemicellulose):\n",
    "            X = pd.DataFrame(np.array([Hydrothermal_temperature, Hydrothermal_time, Particle_size, Solid_to_liquid_ratio, \n",
    "                               Anaerobic_temperature,Anaerobic_time, Lignin, Cellulose, Hemicellulose]).reshape(1, -1),\n",
    "                             columns=preditors)\n",
    "            X = h2o.H2OFrame.from_python(X)\n",
    "            preds = best_model.predict(X)\n",
    "            preds= h2o.as_list(preds)\n",
    "            preds = np.squeeze(np.array(preds))\n",
    "            return preds\n",
    "        #Search scope limitation based on SHAP big data guidance and professional experience\n",
    "        pbounds= {'Hydrothermal_temperature': (130,200),\n",
    "                 'Hydrothermal_time': (0,250),\n",
    "                  \"Particle_size\":(0,40),\n",
    "                 'Solid_to_liquid_ratio': (0,0.2),\n",
    "                  'Anaerobic_temperature': (37.000,37.001),\n",
    "                   'Anaerobic_time': (15,40),\n",
    "                   'Lignin': (10.810,10.811),\n",
    "                  'Cellulose': (34.940,34.941),\n",
    "                  'Hemicellulose': (25.350,25.351)\n",
    "                 }\n",
    "\n",
    "        optimizer_rf = BayesianOptimization(\n",
    "                f=black_box_function,\n",
    "                pbounds=pbounds,\n",
    "                verbose=2,  # verbose = 1 prints only when a maximum is observed, verbose = 0 is silent\n",
    "                \n",
    "            )\n",
    "        optimizer_rf.maximize(\n",
    "                init_points=5,  \n",
    "                n_iter=400               \n",
    "            )\n",
    "\n",
    "        print(optimizer_rf.max)\n",
    "        end = time.time()\n",
    "        print('Running time: %s Seconds'%(end-start))\n",
    "        data_name =r\"D:\\machine learning\\水热机器学习\\data\\data\"+str(i)+\".csv\"\n",
    "        b=pd.DataFrame(np.array(optimizer_rf.max).reshape(-1,1))\n",
    "        b.to_csv(data_name)\n",
    "run_secs(20)\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "file_dir = \"D:/machine learning/水热机器学习/data/\"\n",
    "files = os.listdir(file_dir)\n",
    "df1 = pd.read_csv(os.path.join(file_dir, files[0]))\n",
    "for e in files[1:]:\n",
    "    df2 = pd.read_csv(os.path.join(file_dir, e))\n",
    "    df1 = pd.concat((df1, df2), axis=0, join='inner')\n",
    "print(df1) \n",
    "df1.to_csv(\"Bayes_optimize_data.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
